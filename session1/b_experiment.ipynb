{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Training and monitoring </h1>\n",
    "\n",
    "In this notebook, we will use the taxi rides data in New York City to build a Machine Learning model in support of a fare-estimation tool. The idea is to suggest a likely fare to taxi riders so that they are not surprised, and so that they can protest if the charge is much higher than expected.\n",
    "\n",
    "We will use the linear regression model that comes with Tensorflow to perform the training. We also use TensorBoard to monitor the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import layers\n",
    "import shutil\n",
    "\n",
    "if 'session' in locals() and session is not None:\n",
    "    print('Close interactive session')\n",
    "    session.close()\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Input </h2>\n",
    "\n",
    "Read data in batches.  Instead of using Pandas, we will use add a filename queue to the TensorFlow graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_COLUMNS = ['fare_amount', 'pickuplon','pickuplat','dropofflon','dropofflat','passengers', 'key']\n",
    "LABEL_COLUMN = 'fare_amount'\n",
    "DEFAULTS = [[0.0], [-74.0], [40.0], [-74.0], [40.7], [1.0], ['nokey']]\n",
    "\n",
    "def read_dataset(filename, num_epochs=None, batch_size=512, mode=tf.contrib.learn.ModeKeys.TRAIN):\n",
    "    def _input_fn():\n",
    "        filename_queue = tf.train.string_input_producer([filename], num_epochs=num_epochs, shuffle=True)\n",
    "        reader = tf.TextLineReader()\n",
    "        _, value = reader.read_up_to(filename_queue, num_records=batch_size)\n",
    "\n",
    "        value_column = tf.expand_dims(value, -1)\n",
    "        columns = tf.decode_csv(value_column, record_defaults=DEFAULTS)\n",
    "        features = dict(zip(CSV_COLUMNS, columns))\n",
    "        label = features.pop(LABEL_COLUMN)\n",
    "        return features, label\n",
    "\n",
    "    return _input_fn\n",
    "\n",
    "def get_train():\n",
    "    return read_dataset('./datasets/taxi-train.csv', num_epochs=100, mode=tf.contrib.learn.ModeKeys.TRAIN)\n",
    "\n",
    "def get_valid():\n",
    "    return read_dataset('./datasets/taxi-valid.csv', num_epochs=1, mode=tf.contrib.learn.ModeKeys.EVAL)\n",
    "\n",
    "def get_test():\n",
    "    return read_dataset('./datasets/taxi-test.csv', num_epochs=1, mode=tf.contrib.learn.ModeKeys.EVAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Create features out of input data </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_COLUMNS = [\n",
    "    layers.real_valued_column('pickuplon'),\n",
    "    layers.real_valued_column('pickuplat'),\n",
    "    layers.real_valued_column('dropofflat'),\n",
    "    layers.real_valued_column('dropofflon'),\n",
    "    layers.real_valued_column('passengers'),\n",
    "]\n",
    "\n",
    "feature_cols = INPUT_COLUMNS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Experiment framework </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.contrib.learn as tflearn\n",
    "from tensorflow.contrib.learn.python.learn import learn_runner\n",
    "import tensorflow.contrib.metrics as metrics\n",
    "\n",
    "def experiment_fn(output_dir):\n",
    "    return tflearn.Experiment(\n",
    "        tflearn.LinearRegressor(feature_columns=feature_cols, model_dir=output_dir),\n",
    "        train_input_fn=get_train(),\n",
    "        eval_input_fn=get_valid(),\n",
    "        eval_metrics={\n",
    "            'rmse': tflearn.MetricSpec(\n",
    "                metric_fn=metrics.streaming_root_mean_squared_error\n",
    "            )\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "shutil.rmtree('taxi_trained', ignore_errors=True) # start fresh each time\n",
    "learn_runner.run(experiment_fn, 'taxi_trained')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Monitoring with TensorBoard </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `learn_runner` function above already helped us to write log files needed.\n",
    "\n",
    "* Run `tensorboard --logdir=taxi_trained` in command prompt to launch the tool\n",
    "* Navigate to the URL given, and then go to the \"Events\" tab and \"Graph\" tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2017 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
